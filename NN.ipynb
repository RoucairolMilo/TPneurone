{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMlk1qR73_kK"
   },
   "source": [
    "# Réseaux de neurones artificiels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5woZjpsQ4FYo"
   },
   "source": [
    "## Rétropropagation sur papier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoY77_6a4K7Y"
   },
   "source": [
    "On considère le réseau ci-dessous.\n",
    "\n",
    "<img src=\"https://www.lamsade.dauphine.fr/~airiau/Teaching/exnn.png\" width=500>\n",
    "\n",
    "$d=\\langle (x_1,x_2), (o_1,o_2) \\rangle$ est une donnée de notre base\n",
    "  d'apprentissage: $x_1$ et $x_2$ sont les valeurs en entrée observées\n",
    "  et $o_1$ et $o_2$ sont les valeurs de sorties observées. $x_1$ sera\n",
    "  utilisée en entrée du noeud $X_1$, $x_2$ en entrée du noeud $X_2$ et\n",
    "  $o_1$ sera la valeur attendue pour le noeud $Y_1$ ($o_2$ celle pour\n",
    "  $Y_2$). Les valeurs de sortie calculée par le réseau sont $y_1$ et $y_2$\n",
    "  pour les noeuds $Y_1$ et $Y_2$ et $z_1$, $z_2$ et $z_3$ pour les noeuds\n",
    "  $Z_1$, $Z_2$ et $Z_3$.  On vous rappelle l'algorithme de\n",
    "  rétro propagation ou $x_{ji}$ est l'entrée du noeud $j$ venant du\n",
    "  noeud $i$, $w_{ji}$ est le poids correspondant et $\\delta_n$ est l'erreur associée à l'unité $n$. \n",
    "\n",
    "<img src=\"https://www.lamsade.dauphine.fr/~airiau/Teaching/bprop.png\" width=600>\n",
    "\n",
    "\n",
    "1. Expliquez l'intuition derrière le terme $\\displaystyle \\sum_{k \\in sorties(h)}\n",
    "  w_{k,h}\\delta_k$. D'où provient en fait cette formule?\n",
    "2. Donnez la formule de mise à jour de $w_6$ (qui relie $Z_2$ à\n",
    "  $Y_2$) en fonction de $w_0, \\dots, w_{10}$, $x_1$, $x_2$, $y_1$, $y_2$, $z_1$, $z_2$,\n",
    "  $z_3$, $\\eta$, $o_1$ et $o_2$.\n",
    "3. Faites de même pour la formule de mise à jour de $w_1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST et KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord on charge les données. Ce sont des panda dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "print('la base de données contient %d images qui ont %d pixel'%(X.shape[0], X.shape[1]))\n",
    "def displayData(X,Y):\n",
    "    # set up array\n",
    "    fig, ax = plt.subplots(nrows=8, ncols=8, figsize=(15,15))\n",
    "    fig.suptitle( \"Affichage d'images prises au hasard dans la base\")\n",
    "    # loop over randomly drawn numbers\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            index = np.random.randint(X.shape[0])\n",
    "            #print(X.shape)\n",
    "            #print(X)\n",
    "            #print(np.array(X)[0])\n",
    "            Xnp = np.array(X)\n",
    "            #img = X[index,:].reshape(28,28)\n",
    "            img = Xnp[index].reshape(28,28)\n",
    "            ax[i,j].set_title(\"Valeur: {}\".format(Y[index]))\n",
    "            ax[i,j].imshow(img, cmap='gray_r') \n",
    "            plt.setp(ax[i,j].get_xticklabels(), visible=False)\n",
    "            plt.setp(ax[i,j].get_yticklabels(), visible=False)\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "\n",
    "displayData(X,y)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparez les données en ensmble d'entraineemnt et de test avec `train_test_split` de scikitlearn, pensez à les transformer les en numpy ndarray avec `to_numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisez vos données et assurez vous qu'elles aient la bonne forme. Pour transformer les classes utilisez `keras.utils.to_categorical`, ça transformera une liste de classe en liste correspondant à une sortie souhaitée par le réseau (pour la classification multiclasse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est le moment de penser à l'architecture du réseau. J'ai mit le plus simple réseau auquel j'ai pu penser, il prend un array de 784 en entrée.\n",
    "\n",
    "Keras peut directement prendre les images en entrées, essayez de changer la forme de votre entrée (et des données) pour la présenter sous forme d'image 2D au réseau et obtenir de meilleurs résultats.\n",
    "Vous aurez besoin de `np.reshape` et de regarder la documentaion sur les \"layers\" que keras propose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (784)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez votre modèle en exécutant cette cellule.Vous pouvez essayer d'autres fonctions de perte et d'autres optimsateurs mais ces paramètres devraient permettre de bonnes performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(Xtrain, ytraincat, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour savoir si votre modèle entraîné est performant sur le jeu de test, exécutez cette cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytestcat, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais ce n'est pas la seule façon d'évaluer la précision du modèle, affichez la matrice de confusion avec `confusion_matrix` de scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# à compléter"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ml-tp-08-ann.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
